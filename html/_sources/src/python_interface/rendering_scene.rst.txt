.. _sec-rendering-scene:

渲染场景
=================

在上一节中，我们学习了如何从 XML 文件中加载场景。一旦场景加载完毕，我们就可以按照如下方式开始渲染场景了：

.. code-block:: python

    ...

    # Load the scene for an XML file
    scene = load_file(filename)

    # Get the scene's sensor (if many, can pick one by specifying the index)
    sensor = scene.sensors()[0]

    # Call the scene's integrator to render the loaded scene with the desired sensor
    scene.integrator().render(scene, sensor)

渲染完成后，可以将渲染数据写出为 HDR OpenEXR 文件中，具体如下所示：

.. code-block:: python

    # The rendered data is stored in the film
    film = sensor.film()

    # Write out data as high dynamic range OpenEXR file
    film.set_destination_file('/path/to/output.exr')
    film.develop()

还可以使用 :py:class:`mitsuba.core.Bitmap` 类，将相同的渲染数据经过 gamma tone-mapped 调整输出为 JPEG。

.. code-block:: python

    # Write out a tone-mapped JPG of the same rendering
    from mitsuba.core import Bitmap, Struct
    img = film.bitmap(raw=True).convert(Bitmap.PixelFormat.RGB, Struct.Type.UInt8, srgb_gamma=True)
    img.write('/path/to/output.jpg')

:code:`film.bitmap()` 中的 ``raw=True`` 参数指定了我们是对原始胶片的内容感兴趣，以便能够执行出我们所需转换的格式。

更多有关 bitmap 转换的信息，请参阅 :py:meth:`mitsuba.core.Bitmap.convert`。

可以将储存在 ``Bitmap`` 对象中的数据转换成 NumPy 数组，以便以后在 Python 中进一步处理。

.. code-block:: python

    # Get linear pixel values as a NumPy array for further processing
    img = img.convert(Bitmap.PixelFormat.RGB, Struct.Type.Float32, srgb_gamma=False)
    import numpy as np
    image_np = np.array(img)
    print(image_np.shape)

.. note::

    本示例的完整 Python 脚本可以在该文件中找到👉：:file:`docs/examples/01_render_scene/render_scene.py`
    


.. _sec-rendering-scene-custom:

Custom rendering pipeline in Python
------------------------------------

在接下来的小节中，我们将展示如何使用 Python 绑定编写一个简单的深度图渲染器，这个渲染器会包括光线生成和
像素值 splat 技术，整个完全是由 Python 编写的。显然这比直接调用一个 ``render()`` 集成器会麻烦的多，
但这种细颗粒度的工作在某些应用中可能会很有用。更多信息请参阅相关文档 :ref:`developing custom plugins in Python <sec-custom-plugins>`。

与之前类似，我们导入一些模块并从磁盘中加载场景：

.. literalinclude:: ../../examples/02_depth_integrator/depth_integrator.py
   :language: python
   :lines: 1-21

在本例中我们使用的是 Mitsuba 的 packet 变体。这意味着 Mitsuba 函数的所有调用都是矢量化的，并且
我们在 Python 中避免昂贵的 for 循环。同样的代码也可以跑在 `gpu` 模式的渲染器上。

现在，我们将手动跟踪穿过图像上每个像素的光线，而不是像以前那样直接调用场景上的现成集成器。

.. literalinclude:: ../../examples/02_depth_integrator/depth_integrator.py
   :language: python
   :lines: 23-57

在计算完所有光线与曲面的交点后，我们开始提取深度值：

.. literalinclude:: ../../examples/02_depth_integrator/depth_integrator.py
   :language: python
   :lines: 59-64

随后我们将这些深度值汇集（splat）成 :code:`ImageBlock` ，这是一个能平均周围采样点和解释像素滤波器的数据结构。
随后 :code:`ImageBlock` 被转化成 :code:`Bitmap` 对象并将结果图像保存到磁盘上。

.. literalinclude:: ../../examples/02_depth_integrator/depth_integrator.py
   :language: python
   :lines: 66-84

.. note:: 可以从 :code:`docs/examples/02_depth_integrator/depth_integrator.py` 找到本例的代码。
